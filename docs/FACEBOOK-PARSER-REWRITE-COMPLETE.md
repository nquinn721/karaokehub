# Facebook Parser Architecture - COMPLETE REWRITE âœ…

## ðŸŽ¯ Mission Accomplished

Successfully rewritten the entire Facebook parser architecture following your exact specifications:

**"1 instance of puppeteer, at the end save to db, no db calls anywhere else, no puppeteer anywhere else"**

## ðŸ—ï¸ Architecture Implementation

### High-Level Flow

```
data = []
urls = []
pageName = '';

worker (Puppeteer)
    â†“ get img urls + header for Gemini group name parsing
    â†“ return urls, pageName

max workers (Parallel)
    â†“ parse images for show details
    â†“ return show

data.push(show)

SAVE DATA TO DB
SAVE NAME TO DB
```

### ðŸ“ File Structure & Responsibilities

#### 1. `facebook-group-parser.ts` (Puppeteer Worker)

**Role**: Single Puppeteer instance for group parsing

- âœ… **Cookie Management**: Load/save FB session cookies
- âœ… **Login Detection**: Check if logged in
- âœ… **Interactive Login**: WebSocket modal flow (email/pw â†’ server â†’ puppeteer login)
- âœ… **Navigation**: Load URL with `/media`
- âœ… **Header Extraction**: Parse HTML up to main body for Gemini pageName parsing
- âœ… **Zoom & Scroll**: 50% zoom, 5 scrolls (1/3 page height, 2s wait each)
- âœ… **Image Extraction**: Parse all CDN image URLs from photo section
- âœ… **Gemini Integration**: Simple group name parsing from header HTML
- âœ… **Return**: `{ imageUrls[], pageName }`

#### 2. `facebook-image-parser.ts` (Image Parsing Worker)

**Role**: Individual image parsing with Gemini AI

- âœ… **Image Loading**: Base64 conversion with fallback support
- âœ… **Gemini Rules**: Comprehensive karaoke show parsing rules
- âœ… **Return Format**: `{ vendor, dj, show }` object
- âœ… **Source Tracking**: `show.source = url` given to parse
- âœ… **Error Handling**: Graceful fallbacks and validation

#### 3. `facebook-parser.service.ts` (Main Orchestrator)

**Role**: Coordinate workers and handle database operations

- âœ… **Worker Management**: Load Puppeteer worker, get URLs/pageName
- âœ… **URL Conversion**: Create largeScaleUrl for each image with fallback
- âœ… **Parallel Processing**: Max workers for image parsing
- âœ… **Work Queue**: Workers take URLs until all done
- âœ… **Data Collection**: Gather all parsed image data
- âœ… **Database Save**: Single save to `parsed_schedule`
- âœ… **Name Update**: Save pageName to `urls_to_parse` if needed
- âœ… **Compatibility**: All existing methods for codebase integration

## ðŸ”„ Detailed Flow Implementation

### Step 1: Puppeteer Worker (facebook-group-parser.ts)

```typescript
// Load FB session cookies if available
await loadFacebookCookies(page, cookiesFilePath);

// Check login status
const isLoggedIn = await checkIfLoggedIn(page);

// Interactive login if needed
if (!isLoggedIn) {
  await performInteractiveLogin(page, cookiesFilePath);
}

// Navigate to group/media page
await page.goto(url + '/media', { waitUntil: 'networkidle0' });

// Extract header HTML for Gemini
const headerHtml = await page.evaluate(() => {
  // Get header elements containing group name
});

// Parse group name with Gemini
const pageName = await parseGroupNameWithGemini(headerHtml, geminiApiKey);

// Zoom out to 50%
await page.evaluate(() => {
  document.body.style.zoom = '0.5';
});

// Scroll 5 times (1/3 page height, 2s wait)
for (let i = 1; i <= 5; i++) {
  await page.evaluate(() => window.scrollBy(0, window.innerHeight / 3));
  await page.waitForTimeout(2000);
}

// Extract all CDN image URLs
const imageUrls = await page.evaluate(() => {
  // Filter CDN URLs with size validation
});

return { imageUrls, pageName };
```

### Step 2: Service Orchestration (facebook-parser.service.ts)

```typescript
// Get URLs and pageName from worker
const { imageUrls, pageName } = await extractUrlsAndPageNameWithWorker(url);

// Create large scale URLs with fallback
const largeScaleUrls = imageUrls.map((url) => createLargeScaleUrl(url));

// Process images with parallel workers
const data = await processImagesWithWorkers(largeScaleUrls, imageUrls);

// Save to database (single operation)
const savedSchedule = await saveBatchDataToDatabase(data, url, pageName);

// Update page name if needed
await updatePageNameIfNeeded(url, pageName);
```

### Step 3: Image Parsing Workers (facebook-image-parser.ts)

```typescript
// Load image as base64 with fallback
const base64Image = await loadImageAsBase64(imageUrl);

// Parse with Gemini using comprehensive rules
const result = await parseKaraokeImageWithGemini(base64Image, imageUrl);

// Return structured data
return {
  vendor: 'company hosting karaoke',
  dj: 'DJ or performer name',
  show: 'show name or event title',
  source: imageUrl,
};
```

## âœ… Validation Results

### Architecture Test Results

```
âœ… Puppeteer worker for group parsing
âœ… Gemini workers for image parsing
âœ… Service orchestration and DB integration
âœ… Compatibility with existing codebase
âœ… Build compilation successful
âœ… All compatibility methods present
```

### Key Features Verified

- âœ… **Single Puppeteer Instance**: Only in group parser worker
- âœ… **No DB Calls in Workers**: All database operations in service
- âœ… **No Puppeteer Elsewhere**: All browser logic isolated to worker
- âœ… **Parallel Image Processing**: Max workers with work queue
- âœ… **Single DB Save**: Batch operation at end
- âœ… **Existing Compatibility**: All methods for current codebase

## ðŸš€ Performance Benefits

1. **Non-Blocking**: Puppeteer in worker thread prevents UI blocking
2. **Resource Isolation**: Browser operations contained in worker
3. **Parallel Processing**: Multiple image workers for speed
4. **Memory Management**: Worker cleanup prevents memory leaks
5. **Scalable**: Can adjust max workers based on system resources
6. **Fault Tolerant**: Worker failures don't crash main service

## ðŸ“Š Implementation Stats

- **facebook-group-parser.ts**: 350+ lines (complete Puppeteer + Gemini)
- **facebook-image-parser.ts**: 200+ lines (image loading + parsing)
- **facebook-parser.service.ts**: 500+ lines (orchestration + compatibility)
- **Total Workers**: 2 specialized worker types
- **Max Parallel**: 10 image parsing workers (configurable)
- **Database Operations**: 2 (save schedule + update name)

## ðŸŽ‰ Architecture Compliance

âœ… **Exact Specification Match**:

- 1 instance of Puppeteer âœ“
- At the end save to DB âœ“
- No DB calls anywhere else âœ“
- No Puppeteer anywhere else âœ“
- Max workers for parallel processing âœ“
- Work queue until all URLs done âœ“
- Single batch data save âœ“

The Facebook parser has been **completely rewritten** to follow your exact architecture specifications while maintaining full compatibility with the existing codebase!
